{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Tuner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNi+ldLsZl3IpXtOxhxtOJg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RAVIKUMARBALIJA/tensorflow2_tutorials/blob/main/Keras_Tuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAXYJ7WVzc-j"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmHFT7Rd0Wu-"
      },
      "source": [
        "from keras.datasets import fashion_mnist"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6y-pbcg0mPD",
        "outputId": "e868140b-aece-471e-daa6-144480941c18"
      },
      "source": [
        "pip install keras-tuner"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 13.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 10.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=8cce85011538f8ce75569434f9476b30b546ea4516d5094c335b012ba28d7453\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=c88f965b49d44664f712e179f7b2bfb93753dc0dd06f4576faad9ea6bf133ae1\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqpSih7N0zXn"
      },
      "source": [
        "import kerastuner as kt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXiyWaZQ03wm"
      },
      "source": [
        "from kerastuner.tuners import bayesian,RandomSearch,hyperband"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R41qiO9q64yy",
        "outputId": "a3ea46ac-585e-44bf-e4c3-39f5c10688a8"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=fashion_mnist.load_data()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGueIOgq7I55"
      },
      "source": [
        "x_train=x_train/255.\n",
        "x_test=x_test/255."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C5QLrUp7tCj",
        "outputId": "1afbbbe6-db5f-45bf-b538-f74c8364d64b"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhLwHlsv70vW"
      },
      "source": [
        "from tensorflow.keras.layers import Dense,Input,Dropout,Flatten,InputLayer\n",
        "from tensorflow.keras.models import Sequential,Model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EYRbk_-JxNv"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(28,28)))\n",
        "model.add(Flatten())\n",
        "#hp_units=hp.Int('units',min_value=32,max_value=512,step=32)\n",
        "model.add(Dense(units=500,activation=tf.nn.leaky_relu))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "#hp_learning_rate=hp.choice('learning_rate',values=[0.001,0.002,0.003])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_cross_entropy',metrics=['accuracy'])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6gkzj7n7ck0"
      },
      "source": [
        "def buildModel(hp):\n",
        "  model=Sequential()\n",
        "  model.add(InputLayer(input_shape=(28,28)))\n",
        "  model.add(Flatten())\n",
        "  hp_units=hp.Int('units',min_value=32,max_value=512,step=32)\n",
        "  model.add(Dense(units=hp_units,activation=tf.nn.leaky_relu))\n",
        "  model.add(Dense(10,activation='softmax'))\n",
        "  hp_learning_rate=hp.Choice('learning_rate',values=[0.001,0.002,0.003])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erw8SjTZBmfT",
        "outputId": "693771d9-1b80-4b6e-ccae-ab2739ebbb35"
      },
      "source": [
        "tuner = kt.Hyperband(buildModel,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project my_dir/intro_to_kt/oracle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfP1iYbMMcHr"
      },
      "source": [
        "early_stopping=tf.keras.callbacks.EarlyStopping(patience=5,monitor='val_loss')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGA8bzGxHshx",
        "outputId": "b442c787-77f9-480e-d0ee-2e185bb55010"
      },
      "source": [
        "tuner.search(x_train,y_train,epochs=50,validation_split=0.2,callbacks=[early_stopping])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 30 Complete [00h 00m 40s]\n",
            "val_accuracy: 0.8824999928474426\n",
            "\n",
            "Best val_accuracy So Far: 0.8840833306312561\n",
            "Total elapsed time: 00h 10m 55s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUBgnEcwOlne",
        "outputId": "0d84bf93-57e4-4364-8705-1548b798cf84"
      },
      "source": [
        "best_model=tuner.get_best_models(num_models=1)\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyFFPj6eOmlN"
      },
      "source": [
        "#model.fit()\n",
        "#model.fit(x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, \\\n",
        "#          validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, \\\n",
        " #         sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None,\\ \n",
        "  #        validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTkmwhzuO1H-",
        "outputId": "bfc26524-1d9c-41bb-e068-edc3ea303593"
      },
      "source": [
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 352 and the optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaJam_1msLh6",
        "outputId": "ff09dd19-9a35-4338-f4f0-014a79cc03a7"
      },
      "source": [
        "best_model[0].summary()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 352)               276320    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                3530      \n",
            "=================================================================\n",
            "Total params: 279,850\n",
            "Trainable params: 279,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViYYBaJLsa40",
        "outputId": "12383544-d9bd-493d-9d66-2981a9f74051"
      },
      "source": [
        "model=tuner.hypermodel.build(best_hps)\n",
        "history=model.fit(x_train,y_train,epochs=50,validation_split=0.2)\n",
        "val_acc_per_epoch=history.history['val_accuracy']"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5077 - accuracy: 0.8191 - val_loss: 0.4355 - val_accuracy: 0.8479\n",
            "Epoch 2/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3966 - accuracy: 0.8573 - val_loss: 0.3848 - val_accuracy: 0.8630\n",
            "Epoch 3/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3573 - accuracy: 0.8690 - val_loss: 0.3774 - val_accuracy: 0.8620\n",
            "Epoch 4/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3350 - accuracy: 0.8781 - val_loss: 0.3740 - val_accuracy: 0.8575\n",
            "Epoch 5/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3182 - accuracy: 0.8829 - val_loss: 0.3584 - val_accuracy: 0.8704\n",
            "Epoch 6/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3050 - accuracy: 0.8872 - val_loss: 0.3526 - val_accuracy: 0.8742\n",
            "Epoch 7/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2920 - accuracy: 0.8931 - val_loss: 0.3466 - val_accuracy: 0.8779\n",
            "Epoch 8/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2819 - accuracy: 0.8964 - val_loss: 0.3861 - val_accuracy: 0.8711\n",
            "Epoch 9/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2717 - accuracy: 0.8996 - val_loss: 0.3346 - val_accuracy: 0.8816\n",
            "Epoch 10/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2661 - accuracy: 0.9007 - val_loss: 0.3479 - val_accuracy: 0.8778\n",
            "Epoch 11/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2581 - accuracy: 0.9047 - val_loss: 0.3258 - val_accuracy: 0.8875\n",
            "Epoch 12/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2518 - accuracy: 0.9063 - val_loss: 0.3368 - val_accuracy: 0.8811\n",
            "Epoch 13/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2415 - accuracy: 0.9108 - val_loss: 0.3412 - val_accuracy: 0.8842\n",
            "Epoch 14/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2382 - accuracy: 0.9116 - val_loss: 0.3406 - val_accuracy: 0.8834\n",
            "Epoch 15/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2319 - accuracy: 0.9131 - val_loss: 0.3480 - val_accuracy: 0.8867\n",
            "Epoch 16/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2265 - accuracy: 0.9145 - val_loss: 0.3303 - val_accuracy: 0.8896\n",
            "Epoch 17/50\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2251 - accuracy: 0.9157 - val_loss: 0.3472 - val_accuracy: 0.8887\n",
            "Epoch 18/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2159 - accuracy: 0.9198 - val_loss: 0.3444 - val_accuracy: 0.8889\n",
            "Epoch 19/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2146 - accuracy: 0.9203 - val_loss: 0.3357 - val_accuracy: 0.8896\n",
            "Epoch 20/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2090 - accuracy: 0.9205 - val_loss: 0.3423 - val_accuracy: 0.8869\n",
            "Epoch 21/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2031 - accuracy: 0.9244 - val_loss: 0.3460 - val_accuracy: 0.8887\n",
            "Epoch 22/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2034 - accuracy: 0.9238 - val_loss: 0.3808 - val_accuracy: 0.8810\n",
            "Epoch 23/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1961 - accuracy: 0.9273 - val_loss: 0.3545 - val_accuracy: 0.8858\n",
            "Epoch 24/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1939 - accuracy: 0.9281 - val_loss: 0.3506 - val_accuracy: 0.8915\n",
            "Epoch 25/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1912 - accuracy: 0.9296 - val_loss: 0.3667 - val_accuracy: 0.8895\n",
            "Epoch 26/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1840 - accuracy: 0.9318 - val_loss: 0.3614 - val_accuracy: 0.8878\n",
            "Epoch 27/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1847 - accuracy: 0.9312 - val_loss: 0.3648 - val_accuracy: 0.8882\n",
            "Epoch 28/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1815 - accuracy: 0.9337 - val_loss: 0.3637 - val_accuracy: 0.8907\n",
            "Epoch 29/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1777 - accuracy: 0.9344 - val_loss: 0.4097 - val_accuracy: 0.8867\n",
            "Epoch 30/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1707 - accuracy: 0.9362 - val_loss: 0.4534 - val_accuracy: 0.8734\n",
            "Epoch 31/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1715 - accuracy: 0.9365 - val_loss: 0.4021 - val_accuracy: 0.8839\n",
            "Epoch 32/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1685 - accuracy: 0.9375 - val_loss: 0.4029 - val_accuracy: 0.8878\n",
            "Epoch 33/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1626 - accuracy: 0.9402 - val_loss: 0.3982 - val_accuracy: 0.8886\n",
            "Epoch 34/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1616 - accuracy: 0.9402 - val_loss: 0.3763 - val_accuracy: 0.8930\n",
            "Epoch 35/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1599 - accuracy: 0.9416 - val_loss: 0.4101 - val_accuracy: 0.8839\n",
            "Epoch 36/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1567 - accuracy: 0.9423 - val_loss: 0.3908 - val_accuracy: 0.8917\n",
            "Epoch 37/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1568 - accuracy: 0.9420 - val_loss: 0.4145 - val_accuracy: 0.8855\n",
            "Epoch 38/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1460 - accuracy: 0.9465 - val_loss: 0.4134 - val_accuracy: 0.8871\n",
            "Epoch 39/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1494 - accuracy: 0.9454 - val_loss: 0.4250 - val_accuracy: 0.8859\n",
            "Epoch 40/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1522 - accuracy: 0.9448 - val_loss: 0.4149 - val_accuracy: 0.8859\n",
            "Epoch 41/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1416 - accuracy: 0.9479 - val_loss: 0.4180 - val_accuracy: 0.8855\n",
            "Epoch 42/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1441 - accuracy: 0.9471 - val_loss: 0.4601 - val_accuracy: 0.8746\n",
            "Epoch 43/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1388 - accuracy: 0.9481 - val_loss: 0.4017 - val_accuracy: 0.8957\n",
            "Epoch 44/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1405 - accuracy: 0.9476 - val_loss: 0.4903 - val_accuracy: 0.8763\n",
            "Epoch 45/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1335 - accuracy: 0.9508 - val_loss: 0.4058 - val_accuracy: 0.8930\n",
            "Epoch 46/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1325 - accuracy: 0.9520 - val_loss: 0.5366 - val_accuracy: 0.8767\n",
            "Epoch 47/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1338 - accuracy: 0.9515 - val_loss: 0.4818 - val_accuracy: 0.8783\n",
            "Epoch 48/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1311 - accuracy: 0.9513 - val_loss: 0.4207 - val_accuracy: 0.8908\n",
            "Epoch 49/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1302 - accuracy: 0.9533 - val_loss: 0.4717 - val_accuracy: 0.8882\n",
            "Epoch 50/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1311 - accuracy: 0.9526 - val_loss: 0.5581 - val_accuracy: 0.8674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj8u61UcwBGq"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flNUi-qFtDtV"
      },
      "source": [
        "best_epoch=np.argmax(val_acc_per_epoch)+1"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI4DwZM7v8NC",
        "outputId": "d27cdeab-e5ca-4568-f813-d8b7840a0a59"
      },
      "source": [
        "val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpA94EBowOwM",
        "outputId": "faf67937-e368-490a-f410-be82143ef23c"
      },
      "source": [
        "hypermodel=tuner.hypermodel.build(best_hps)\n",
        "history=hypermodel.fit(x_train,y_train,epochs=best_epoch,validation_split=0.2)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5076 - accuracy: 0.8204 - val_loss: 0.4463 - val_accuracy: 0.8353\n",
            "Epoch 2/43\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3936 - accuracy: 0.8583 - val_loss: 0.3937 - val_accuracy: 0.8611\n",
            "Epoch 3/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3606 - accuracy: 0.8684 - val_loss: 0.3637 - val_accuracy: 0.8727\n",
            "Epoch 4/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3335 - accuracy: 0.8782 - val_loss: 0.3433 - val_accuracy: 0.8774\n",
            "Epoch 5/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3196 - accuracy: 0.8836 - val_loss: 0.3571 - val_accuracy: 0.8710\n",
            "Epoch 6/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3030 - accuracy: 0.8886 - val_loss: 0.3431 - val_accuracy: 0.8778\n",
            "Epoch 7/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2912 - accuracy: 0.8930 - val_loss: 0.3835 - val_accuracy: 0.8697\n",
            "Epoch 8/43\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2808 - accuracy: 0.8954 - val_loss: 0.3404 - val_accuracy: 0.8799\n",
            "Epoch 9/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2727 - accuracy: 0.8991 - val_loss: 0.3360 - val_accuracy: 0.8833\n",
            "Epoch 10/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2653 - accuracy: 0.9018 - val_loss: 0.3350 - val_accuracy: 0.8814\n",
            "Epoch 11/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2560 - accuracy: 0.9052 - val_loss: 0.3541 - val_accuracy: 0.8778\n",
            "Epoch 12/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2499 - accuracy: 0.9068 - val_loss: 0.3618 - val_accuracy: 0.8724\n",
            "Epoch 13/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2413 - accuracy: 0.9099 - val_loss: 0.3980 - val_accuracy: 0.8688\n",
            "Epoch 14/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2353 - accuracy: 0.9117 - val_loss: 0.3424 - val_accuracy: 0.8822\n",
            "Epoch 15/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2276 - accuracy: 0.9150 - val_loss: 0.3382 - val_accuracy: 0.8851\n",
            "Epoch 16/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2254 - accuracy: 0.9158 - val_loss: 0.3357 - val_accuracy: 0.8873\n",
            "Epoch 17/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2197 - accuracy: 0.9171 - val_loss: 0.3170 - val_accuracy: 0.8949\n",
            "Epoch 18/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2150 - accuracy: 0.9197 - val_loss: 0.3199 - val_accuracy: 0.8930\n",
            "Epoch 19/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2088 - accuracy: 0.9221 - val_loss: 0.4115 - val_accuracy: 0.8698\n",
            "Epoch 20/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2091 - accuracy: 0.9216 - val_loss: 0.3278 - val_accuracy: 0.8936\n",
            "Epoch 21/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1997 - accuracy: 0.9253 - val_loss: 0.3763 - val_accuracy: 0.8822\n",
            "Epoch 22/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2007 - accuracy: 0.9255 - val_loss: 0.3490 - val_accuracy: 0.8867\n",
            "Epoch 23/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1966 - accuracy: 0.9265 - val_loss: 0.3788 - val_accuracy: 0.8842\n",
            "Epoch 24/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1911 - accuracy: 0.9291 - val_loss: 0.3744 - val_accuracy: 0.8781\n",
            "Epoch 25/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1913 - accuracy: 0.9282 - val_loss: 0.3624 - val_accuracy: 0.8911\n",
            "Epoch 26/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1819 - accuracy: 0.9324 - val_loss: 0.4134 - val_accuracy: 0.8764\n",
            "Epoch 27/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1836 - accuracy: 0.9313 - val_loss: 0.3808 - val_accuracy: 0.8830\n",
            "Epoch 28/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1799 - accuracy: 0.9335 - val_loss: 0.3707 - val_accuracy: 0.8877\n",
            "Epoch 29/43\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1739 - accuracy: 0.9341 - val_loss: 0.3997 - val_accuracy: 0.8822\n",
            "Epoch 30/43\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1732 - accuracy: 0.9361 - val_loss: 0.4105 - val_accuracy: 0.8816\n",
            "Epoch 31/43\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1684 - accuracy: 0.9377 - val_loss: 0.4011 - val_accuracy: 0.8867\n",
            "Epoch 32/43\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1705 - accuracy: 0.9376 - val_loss: 0.3818 - val_accuracy: 0.8896\n",
            "Epoch 33/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1598 - accuracy: 0.9404 - val_loss: 0.4067 - val_accuracy: 0.8843\n",
            "Epoch 34/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1611 - accuracy: 0.9392 - val_loss: 0.4047 - val_accuracy: 0.8850\n",
            "Epoch 35/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1596 - accuracy: 0.9423 - val_loss: 0.4238 - val_accuracy: 0.8825\n",
            "Epoch 36/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1550 - accuracy: 0.9427 - val_loss: 0.4360 - val_accuracy: 0.8802\n",
            "Epoch 37/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1606 - accuracy: 0.9400 - val_loss: 0.4058 - val_accuracy: 0.8844\n",
            "Epoch 38/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1508 - accuracy: 0.9444 - val_loss: 0.3867 - val_accuracy: 0.8913\n",
            "Epoch 39/43\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1497 - accuracy: 0.9449 - val_loss: 0.3900 - val_accuracy: 0.8898\n",
            "Epoch 40/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1485 - accuracy: 0.9450 - val_loss: 0.4093 - val_accuracy: 0.8875\n",
            "Epoch 41/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1478 - accuracy: 0.9462 - val_loss: 0.4111 - val_accuracy: 0.8893\n",
            "Epoch 42/43\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1408 - accuracy: 0.9473 - val_loss: 0.4002 - val_accuracy: 0.8891\n",
            "Epoch 43/43\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1384 - accuracy: 0.9491 - val_loss: 0.4473 - val_accuracy: 0.8790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WilUrCQwfuy"
      },
      "source": [
        "hyper"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}